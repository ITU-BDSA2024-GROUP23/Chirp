{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"report/","title":"_Chirp!_ Project Report","text":"<p>\\newpage </p>"},{"location":"report/#design-and-architecture","title":"Design and architecture","text":""},{"location":"report/#domain-model","title":"Domain model","text":"<p>The centerpiece of our domain model is the User class. It inherits from the ASP.NET's IdentityUser class allowing us to use ASP.NET Identity to manage our users. This offloads a lot of heavy lifting such as login, registration and authentication, instead letting us focus on developing other essential features for Chirp. All other classes in the domain model are dependent on the User class. Whether it would be a Cheep requiring an author, or a Like requiring a liker, they all must reference an instance of a User. This, in combination with ASP.NET Identity, makes it easy to verify that only authenticated users can make certain interactions with the site, such as following people and writing/liking cheeps. An illustration of our domain model can be seen below:</p> <p></p>"},{"location":"report/#architecture-in-the-small","title":"Architecture \u2014 In the small","text":"<p>The architecture of our Chirp application is based on the \"Onion Architecture\" pattern. This pattern is a layered architecture that enforces separation of concerns and invites a clear dependency flow. </p> <p></p> <p>At the center of the application is the Core layer. This layer contains the domain model, interfaces, and DTOs. As seen in the diagram, the \"Core\" layer is dependent on nothing, but is depended on by many other layers. This is, as mentioned, a key principle of the Onion Architecture pattern.</p> <p>The Infrastructure layer is responsible for data access, migrations, seeding, and our services. This layer is dependent on the Core layer, as it needs to interact with the domain model.</p> <p>The outermost layer is the Web layer. This layer is responsible for delivering the application to the user. It uses ASP.NET Core to handle HTTP requests and is responsible for rendering the pages. Furthermore, it has the application's entry point, the <code>Program</code> class, which is responsible for configuring the application and starting the server.</p>"},{"location":"report/#architecture-of-deployed-application","title":"Architecture of deployed application","text":"<ol> <li>Microsoft Azure Server:<ul> <li>The application server is hosted on Azure App Service.</li> <li>It handles incoming requests, logic and interactions with the database.</li> </ul> </li> <li>User Interaction:<ul> <li>Users interact with the application through their browser</li> <li>The browser sends HTTP requests to the server hosted on Azure for secure communication.</li> </ul> </li> <li>Database Communication:<ul> <li>The server queries our SQLite database to retrieve and or store data</li> </ul> </li> <li>Third-Party Authentication:<ul> <li>Users login or sign in via Github Authentication, which is depicted in the er diagram</li> </ul> </li> </ol>"},{"location":"report/#user-activities","title":"User activities","text":""},{"location":"report/#legend","title":"Legend","text":"<p>In the following section, multiple flowcharts will visualize the possible journeys through the application.  Before showing how a user can interact with the chirp application, the diagrams are going to follow these different legends:</p> <p></p> <p>\\newpage</p>"},{"location":"report/#unauthorized","title":"Unauthorized","text":"<p>To show how a user can interact with the website while being logged out, we have made an 'Unauthorized' flowchart:</p> <p></p> <p>\\newpage</p>"},{"location":"report/#authorized","title":"Authorized","text":"<p>When a user has logged in or signed up, they now have authorized access. This grants the user more possibilities on the Chirp platform, visualized in the 'Authorized' flowchart:</p> <p></p> <p>\\newpage</p>"},{"location":"report/#complete","title":"Complete","text":"<p>To see the full picture of how it all works together in tandem, the whole application is laid out in the 'Complete' flowchart:</p> <p></p> <p>\\newpage</p>"},{"location":"report/#sequence-of-functionalitycalls-trough-chirp","title":"Sequence of functionality/calls trough Chirp!","text":"<p>We have made a sequence diagram showing the flow of messages and data when an unauthorized user visits our homepage. The diagram can be seen below:</p> <p></p> <p>\\newpage</p>"},{"location":"report/#process","title":"Process","text":""},{"location":"report/#build-test-release-and-deployment","title":"Build, test, release, and deployment","text":""},{"location":"report/#pipeline","title":"Pipeline","text":"<p>This is our pipeline workflow which job is to combine the other workflows. This defines different jobs in order to make sure workflow depend on each other in the correct way. This is needed since some workflows reads the output of others, as well as sometimes workflows should not even run if an other workflows fail.</p>"},{"location":"report/#prepare-pipeline","title":"Prepare pipeline","text":"<p>This is our prepare pipeline workflow which declares variables that other workflows uses. This is done in different ways like reading what branch the pipeline is running on or reading file contents in the repository. This workflow then outputs these variables as well as a summary. Other workflows can then use these variables to implement logic that defines the behavior of individual jobs and steps.</p>"},{"location":"report/#linting-and-testing","title":"Linting and testing","text":"<p>This workflow is responsible for testing and linting our project. Testing is done on both Windows and Linux runners, which ensures the project is compatible for both Windows and Linux. If the tests fail, the pipeline stops, and linting does not run. The linting part validates code formatting using <code>dotnet format --verify-no-changes</code>. This ensures formatting issues are resolved before commits through git hooks. </p> <p>\\newpage</p>"},{"location":"report/#build-and-release","title":"Build and release","text":"<p>This workflow builds the application and generates either full releases or pre-releases. For the <code>main</code> branch, a full release is created while the <code>staging</code> branch generates a pre-release that includes the short SHA of the latest commit in its version. Both full releases and pre-releases are built for multiple platforms including Windows, Linux, and macOS. The releases follow the \"SemVer\" semantic versioning standard, which is validated through a regex in the pipeline. Using SemVer forced us to consider when to make major, minor, or patch releases. However, since we implemented SemVer quite late in the project, we didn't really work with it until the end.</p> <p>\\newpage</p>"},{"location":"report/#deploy-to-azure","title":"Deploy to Azure","text":"<p>This workflow handles the deployment of the application to Azure and is executed only from the <code>main</code> branch to publish the application to production. For branches like staging, deployment jobs are skipped because a staging slot in Azure costs money, and we didn't want half done code to be deployed to production.</p> <p>\\newpage</p>"},{"location":"report/#team-work","title":"Team work","text":""},{"location":"report/#project-board","title":"Project board","text":"<p>In the end of the project, almost all of our issues are resolved. The only issue missing is an the one where we will need to add authed integration tests. We did not resolve this issue because we ran into some problems while working on it. The problem was that we had no way to fake an identity that we could use for these tests. Since the priority was only normal, which meant that we had other issues that was more important, we decided to postpone that issue till we had time to figure out a solution. As of 18th of december 2024, 1 day before our hand-in we did not have time to figure out a solution for this issue. You can see that in total, we managed to resolve 62 issues out of 63 which we think is very good.</p> <p>As of missing features, the only feature we talked about implementing that we did not managed to, was a profile picture feature. The reason we did not implement this, was because we had no time left to address and plan a solution of how to implement this feature, before we had to deliver this project.</p>"},{"location":"report/#from-issue-to-production","title":"From issue to production","text":"<p>When a contributor wants to create a new issue, the first thing they will do is go to the GitHub repository and find the <code>Issues</code> sections. The contributor will then find and click on the <code>new issue</code> button and will be prompted to select an issue template, where in our case there is only one. The template will help them fill out the issue in a generic way with an issue description and some acceptance criteria if necessary. When the issue is created, it will soon be labeled and assigned to a developer, as well as our Chirp project board. On the project board it will also be given a status, priority as well as an optional week, start date and end date. We also use milestones to keep track of when issues need to be done. As an example our milestones was the project reviews and the project presentation.</p> <p>The issue is now ready for a contributor to pickup and start working on it. First step is to branch out from our <code>staging</code> branch to create a new feature branch. This branch needs to follow the naming conventions described in the README.md. When the development of the issue progresses, the contributor will update the acceptance criteria marking them complete, as well as clear out any complications that might occur under development. When all acceptance criteria are marked completed, the contributor will create a pull request from the feature branch back into the <code>staging</code> branch. On all branches, our pipeline (GitHub workflow) will run all our tests as well as lint our code on every commit. This workflow needs to complete successfully before a merge from the feature branch is available, as well as at least 2 people needs to review and accept the incoming changes in the pull request. When the pull request is merged into <code>staging</code>, our pipeline will be triggered for the staging branch that runs all the same steps as well as creating a pre-release for the version. The pipeline includes a version check against the official SemVer regex. If this fails, the pipeline will crash before creating the pre-release.</p> <p>When necessary, we will make sure everything works as expected on the <code>staging</code> branch, creating new test for errors we find and at last create a pull request from <code>staging</code> into our <code>main</code> branch. When the pull-request is accepted, it will again trigger our pipeline which will automatically verify the version again and also make sure that no previous releases exists of that version. If everything is fine, our pipeline will create a release. We then update the release note to include all changes made referencing the issues we resolved in this version bump. The pipeline will also deploy our new version of the application to Azure.</p> <p>\\newpage</p>"},{"location":"report/#how-to-make-chirp-work-locally","title":"How to make Chirp! work locally","text":"<p>To run and clone the project you need the following prerequisites:</p> <ul> <li> <p>.NET 7 (for running the application)</p> <ul> <li>Installation link</li> <li>Setup guide</li> </ul> </li> <li> <p>Git CLI (for cloning the repository)</p> <ul> <li>Installation link</li> <li>Setup guide</li> </ul> </li> </ul> <p>After the installation of the prerequisites, you can clone the repository by running the following command in your terminal:</p> <p><pre><code>git clone https://github.com/ITU-BDSA2024-GROUP23/Chirp.git\n</code></pre> Now that you have cloned our repository, you should navigate to <code>Chirp.Web</code> by running the following command in your terminal:</p> <pre><code>cd ./Chirp/src/Chirp.Web\n</code></pre> <p>Before running the application, you need to set up the GitHub oAuth secrets. This can be done by running the following commands in your terminal:</p> <pre><code>dotnet user-secrets set \"GH_CLIENT_ID\" &lt;YOUR_GITHUB_CLIENT_ID&gt;\ndotnet user-secrets set \"GH_CLIENT_SECRET\" &lt;YOUR_GITHUB_CLIENT_SECRET&gt;\n</code></pre> <p>Replace <code>YOUR_GITHUB_CLIENT_ID</code> and <code>YOUR_GITHUB_CLIENT_SECRET</code> with your own GitHub oAuth application secrets. If you haven't already created a GitHub oAuth application it can be done here. It is important that the callback URL is <code>http://localhost:5273/auth/github</code> and the homepage URL is <code>http://localhost:5273</code>.</p> <p>Finally, you can run the application by running the following command in your terminal. Please make sure you are in the <code>Chirp.Web</code> directory:</p> <pre><code>dotnet run\n</code></pre>"},{"location":"report/#how-to-run-test-suite-locally","title":"How to run test suite locally","text":"<p>If you haven't already, please refer to the \"How to make Chirp! work locally\" section to set up the prerequisites for installing .NET 7, Git CLI, and cloning the repository. Also, make sure you have set up the GitHub oAuth secrets as also described in the previous section.</p> <ol> <li>Install PowerShell if you haven't already.<ul> <li>Instructions for installing PowerShell can be found here.</li> </ul> </li> <li> <p>Navigate to the root of the project in your terminal.</p> <pre><code>cd ./Chirp\n</code></pre> </li> <li> <p>Make sure Playwright is installed - if not, run the following command in the root of the project:</p> <pre><code>pwsh test/PlaywrightTests/bin/Debug/net7.0/playwright.ps1 install --with-deps\n</code></pre> </li> <li> <p>Run the tests</p> <pre><code>dotnet test\n</code></pre> </li> </ol>"},{"location":"report/#ethics","title":"Ethics","text":""},{"location":"report/#license","title":"License","text":"<p>We are using an Apache 2.0 license.</p>"},{"location":"report/#llms-chatgpt-copilot-and-others","title":"LLMs, ChatGPT, CoPilot, and others","text":"<p>In the development of Chirp! we have used two different large language models (LLMs) to help us with the development. The first one being GitHub Copilot and the second one being ChatGPT. While Copilot was being used constantly for small code completions, ChatGPT was more useful for finding ways to attack an issue or finding libraries to solve an issue. </p> <p>The responses of ChatGPT were often wrong or incomplete, since it didn't have the full picture of the project. This meant that we had to remain critical of the responses, and not just blindly accept the answer. Since the responses were often wrong or misleading, we had to spend more time on the issue than if we had just solved it ourselves or remained critical. ChatGPT was more helpful when it came to more simple stuff such as Unit tests with given context. The use of Copilot was more successful, since it was used for small code completions, where the context was clear, which sped up the development process.</p> <p>When it comes to co-authoring, we did not perceive these tools as significant contributors. There has been a few cases where their solution was used, and therefore we referenced them in the code.</p>"}]}